{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code_cham_tno(v2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHfCfKPR99_0"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Auto-Scores-National-Multiple-Choice-Test-master\")\n",
        "import imutils\n",
        "import numpy as np\n",
        "import cv2\n",
        "from math import ceil\n",
        "from model import CNN_Model\n",
        "from collections import defaultdict\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd\n",
        "#from openpyxl import load_workbook\n",
        "import math\n",
        "from xlwt import Workbook\n",
        "wb = Workbook()\n",
        "sheet1 = wb.add_sheet('sheet 1')\n",
        "sheet1.write(0, 0, 'STT')\n",
        "sheet1.write(0, 1, 'Số báo danh')\n",
        "sheet1.write(0, 2, 'Mã đề thi')\n",
        "sheet1.write(0, 3, 'Kết quả')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qOOOBXq-DV8"
      },
      "source": [
        "def get_x(s):\n",
        "    return s[1][0]\n",
        "def get_y(s):\n",
        "    return s[1][1]\n",
        "def get_h(s):\n",
        "    return s[1][3]\n",
        "def get_x_ver1(s):\n",
        "    s = cv2.boundingRect(s)\n",
        "    return s[0] * s[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXZNjpnQ-E0E"
      },
      "source": [
        "def crop_image(img):\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    #cv2_imshow(gray_img)\n",
        "    blurred = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
        "    #cv2_imshow(blurred)\n",
        "    img_canny = cv2.Canny(blurred, 100, 200)\n",
        "    #cv2_imshow(img_canny)\n",
        "\n",
        "    # find contours\n",
        "    cnts = cv2.findContours(img_canny.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "\n",
        "    ans_blocks = []\n",
        "    x_old, y_old, w_old, h_old = 0, 0, 0, 0\n",
        "\n",
        "    # ensure that at least one contour was found\n",
        "    if len(cnts) > 0:\n",
        "        # sort the contours according to their size in descending order\n",
        "        cnts = sorted(cnts, key=get_x_ver1)\n",
        "\n",
        "        # loop over the sorted contours\n",
        "        for i, c in enumerate(cnts):\n",
        "            x_curr, y_curr, w_curr, h_curr = cv2.boundingRect(c)\n",
        "\n",
        "            if w_curr * h_curr > 100000:\n",
        "                # check overlap contours\n",
        "                check_xy_min = x_curr * y_curr - x_old * y_old\n",
        "                check_xy_max = (x_curr + w_curr) * (y_curr + h_curr) - (x_old + w_old) * (y_old + h_old)\n",
        "\n",
        "                # if list answer box is empty\n",
        "                if len(ans_blocks) == 0:\n",
        "                    ans_blocks.append(\n",
        "                        (gray_img[y_curr:y_curr + h_curr, x_curr:x_curr + w_curr], [x_curr, y_curr, w_curr, h_curr]))\n",
        "                    # update coordinates (x, y) and (height, width) of added contours\n",
        "                    x_old = x_curr\n",
        "                    y_old = y_curr\n",
        "                    w_old = w_curr\n",
        "                    h_old = h_curr\n",
        "                elif check_xy_min > 20000 and check_xy_max > 20000:\n",
        "                    ans_blocks.append(\n",
        "                        (gray_img[y_curr:y_curr + h_curr, x_curr:x_curr + w_curr], [x_curr, y_curr, w_curr, h_curr]))\n",
        "                    # update coordinates (x, y) and (height, width) of added contours\n",
        "                    x_old = x_curr\n",
        "                    y_old = y_curr\n",
        "                    w_old = w_curr\n",
        "                    h_old = h_curr\n",
        "\n",
        "        # sort ans_blocks according to x coordinate\n",
        "        sorted_ans_blocks = sorted(ans_blocks, key=get_x)\n",
        "        return sorted_ans_blocks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9QW6lul-H6C"
      },
      "source": [
        "def process_ans_blocks(ans_blocks):\n",
        "    list_answers = []\n",
        "    # Loop over each block ans in\n",
        "    for ans_block in ans_blocks:\n",
        "        ans_block_img = np.array(ans_block[0])\n",
        "        offset1 = ceil(ans_block_img.shape[0] / 6)\n",
        "        # Loop over each box in answer block\n",
        "        for i in range(6):\n",
        "            box_img = np.array(ans_block_img[i * offset1:(i + 1) * offset1, :])\n",
        "            height_box = box_img.shape[0]\n",
        "            \n",
        "            box_img = box_img[14:height_box - 14, :]\n",
        "            offset2 = ceil(box_img.shape[0] / 5)\n",
        "\n",
        "            # loop over each line in a box\n",
        "            for j in range(5):\n",
        "                list_answers.append(box_img[j * offset2:(j + 1) * offset2, :])\n",
        "\n",
        "    return list_answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A--VHMie-KBl"
      },
      "source": [
        "def process_list_ans(list_answers):\n",
        "    list_choices = []\n",
        "    offset = 44\n",
        "    start = 32\n",
        "\n",
        "    for answer_img in list_answers:\n",
        "        for i in range(4):\n",
        "            bubble_choice = answer_img[:, start + i * offset:start + (i + 1) * offset]\n",
        "            bubble_choice = cv2.threshold(bubble_choice, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
        "            bubble_choice = cv2.resize(bubble_choice, (28, 28), cv2.INTER_AREA)\n",
        "            #cv2_imshow(bubble_choice)\n",
        "            bubble_choice = bubble_choice.reshape((28, 28, 1))\n",
        "            list_choices.append(bubble_choice)\n",
        "\n",
        "    if len(list_choices) != 480:\n",
        "        raise ValueError(\"Length of list_choices must be 480\")\n",
        "    return list_choices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7vTMM7U-L5e"
      },
      "source": [
        "def map_answer(idx):\n",
        "    if idx % 4 == 0:\n",
        "        answer_circle = \"A\"\n",
        "    elif idx % 4 == 1:\n",
        "        answer_circle = \"B\"\n",
        "    elif idx % 4 == 2:\n",
        "        answer_circle = \"C\"\n",
        "    else:\n",
        "        answer_circle = \"D\"\n",
        "    return answer_circle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JJc5LIwtap6"
      },
      "source": [
        "\n",
        "def drawText(image, txt):\n",
        "\t# font\n",
        "\tfont = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\t# org\n",
        "\torg = (50, 50)\n",
        "\t# fontScale\n",
        "\tfontScale = 1\n",
        "\t# Blue color in BGR\n",
        "\tcolor = (130, 130, 0)\n",
        "\t# Line thickness of 2 px\n",
        "\tthickness = 2\n",
        "\t# Using cv2.putText() method\n",
        "\timage = cv2.putText(image, txt, org, font,\n",
        "\t\t\t\t\t\tfontScale, color, thickness, cv2.LINE_AA)\n",
        "\treturn\n",
        "\n",
        "# Ham tinh khoang cach giua hai deim\n",
        "def distance(p1,p2):\n",
        "    my_dist = math.sqrt(((p1[0] - p2[0]) ** 2) + ((p1[1] - p2[1]) ** 2))\n",
        "    return  my_dist\n",
        "\n",
        "def sort_contours(cnts, method=\"left-to-right\"):\n",
        "\t# initialize the reverse flag and sort index\n",
        "\treverse = False\n",
        "\ti = 0\n",
        "\t# handle if we need to sort in reverse\n",
        "\tif method == \"right-to-left\" or method == \"bottom-to-top\":\n",
        "\t\treverse = True\n",
        "\t# handle if we are sorting against the y-coordinate rather than\n",
        "\t# the x-coordinate of the bounding box\n",
        "\tif method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
        "\t\ti = 1\n",
        "\t# construct the list of bounding boxes and sort them from top to\n",
        "\t# bottom\n",
        "\tboundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
        "\t(cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
        "\t\tkey=lambda b:b[1][i], reverse=reverse))\n",
        "\t# return the list of sorted contours and bounding boxes\n",
        "\treturn (cnts, boundingBoxes)\n",
        "\n",
        "def order_points(pts):\n",
        "\n",
        "\trect = np.zeros((4, 2), dtype=\"float32\")\n",
        "\n",
        "\ts = pts.sum(axis=1)\n",
        "\trect[0] = pts[np.argmin(s)]\n",
        "\trect[2] = pts[np.argmax(s)]\n",
        "\n",
        "\tdiff = np.diff(pts, axis=1)\n",
        "\trect[1] = pts[np.argmin(diff)]\n",
        "\trect[3] = pts[np.argmax(diff)]\n",
        "\n",
        "\t# return the ordered coordinates\n",
        "\treturn rect\n",
        "\n",
        "def four_point_transform(image, pts):\n",
        "\n",
        "\n",
        "\trect = order_points(pts)\n",
        "\t(tl, tr, br, bl) = rect\n",
        "\n",
        "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "\tmaxWidth = max(int(widthA), int(widthB))\n",
        "\n",
        "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "\tmaxHeight = max(int(heightA), int(heightB))\n",
        "\n",
        "\tdst = np.array([\n",
        "\t\t[0, 0],\n",
        "\t\t[maxWidth - 1, 0],\n",
        "\t\t[maxWidth - 1, maxHeight - 1],\n",
        "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
        "\t# compute the perspective transform matrix and then apply it\n",
        "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
        "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
        "\t# return the warped image\n",
        "\treturn warped\n",
        "\n",
        "def find_corner_by_rotated_rect(box,approx):\n",
        "    corner = []\n",
        "    for p_box in box:\n",
        "        min_dist = 999999999\n",
        "        min_p = None\n",
        "        for p in approx:\n",
        "            dist = distance(p_box, p[0])\n",
        "            if dist < min_dist:\n",
        "                min_dist = dist\n",
        "                min_p = p[0]\n",
        "        corner.append(min_p)\n",
        "\n",
        "    corner = np.array(corner)\n",
        "    return corner\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzQlLBmg4vzX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-k9K0Itu7F8"
      },
      "source": [
        "def find_area(input,image) :\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    # Làm mờ ảnh bằng hàm GaussianBlur giảm nhiễu\n",
        "    blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "    #cv2.imshow('cam', blurred)\n",
        "    #cv2.waitKey(30)\n",
        "    # Threshol lấy ngưỡng thích ứng và độ giãn nở để hiển thị các tính năng chính của hình ảnh\n",
        "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "    #cv2.imshow(\"Anh nhị phân \", thresh)\n",
        "    #cv2.waitKey()\n",
        "    # 3. Tim khung ben ngoai de tach van ban khoi nen\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    # sắp xếp các counter theo diện tích\n",
        "    contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
        "    approx = cv2.approxPolyDP(contours[input], 0.008 * cv2.arcLength(contours[input], True), True)\n",
        "    rect = cv2.minAreaRect(contours[input])\n",
        "    box = cv2.boxPoints(rect)\n",
        "\n",
        "    #Thuc hien transform de xoay van ban\n",
        "    corner = find_corner_by_rotated_rect(box,approx)\n",
        "    image = four_point_transform(image,corner)\n",
        "    wrap = four_point_transform(thresh,corner)\n",
        "\n",
        "    #resize vùng báo danh\n",
        "    width = int(image.shape[1] * 2)\n",
        "    height = int(image.shape[0] * 2)\n",
        "    dim = (width, height)\n",
        "    image2=cv2.resize(image.copy(),dim,interpolation=cv2.INTER_AREA)\n",
        "    gray_img = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
        "    # remove noise by blur image and threshold\n",
        "    blurred_2 = cv2.GaussianBlur(gray_img, (9, 9), 0)\n",
        "    thresh_2 = cv2.adaptiveThreshold(blurred_2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
        "    #trả về ảnh nhị phân vùng số báo danh sau khi phóng to\n",
        "    return thresh_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JuKNJl4vDz_"
      },
      "source": [
        "def findcorrect(thresh_2):\n",
        "    contours = cv2.findContours(thresh_2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = imutils.grab_contours(contours)\n",
        "    tickcontours = []\n",
        "    for c in contours:\n",
        "        approx1 = cv2.approxPolyDP(c, 0.001 * cv2.arcLength(c, True), True)\n",
        "        (x, y, w, h) = cv2.boundingRect(c)\n",
        "        ar = w / float(h)\n",
        "        r= w/2\n",
        "        area = cv2.contourArea(c)\n",
        "        if w >= 29 and h >= 28 and 0.9 <= ar <= 1.1 and len(approx1) > 7:\n",
        "            tickcontours.append(c)\n",
        "            #print(w, h)\n",
        "    tickcontours = sort_contours(tickcontours, method=\"left-to-right\")[0]\n",
        "    correct = '' # bien luu so bao danh\n",
        "    a=0\n",
        "    count = 0 # xac dinh vi tri to mau tren moi cot\n",
        "    #print(len(tickcontours))\n",
        "    for (q, i) in enumerate(np.arange(0, len(tickcontours), 10)):\n",
        "\n",
        "        # Dinh nghia mau rieng cho tung cot\n",
        "        color = (100,a,1)\n",
        "        a+=50\n",
        "        # Sap xep cac contour theo cot\n",
        "        cnts = sort_contours(tickcontours[i:i + 10], method=\"top-to-bottom\")[0]\n",
        "        #cv2.drawContours(image2, cnts, -1, color, 3)\n",
        "        #print(q, i)\n",
        "        choice = None\n",
        "        total = 0\n",
        "        # Duyet qua cac contour trong cot\n",
        "        for (j, c) in enumerate(cnts):\n",
        "            #print (\"j=\",j)\n",
        "            # Tao mask de xem muc do to mau cua contour\n",
        "            mask = np.zeros(thresh_2.shape, dtype= \"uint8\")\n",
        "            cv2.drawContours(mask, [c],-1 , 255, -1)\n",
        "            mask = cv2.bitwise_and(thresh_2, thresh_2, mask= mask)\n",
        "            total = cv2.countNonZero(mask)\n",
        "            #print(total)\n",
        "            # Lap de chon contour to mau dam nhat\n",
        "            if choice is None or total > choice[0]:\n",
        "               choice = (total, j)\n",
        "               # Neu dung Thi to mau xanh\n",
        "               count = j\n",
        "               color = (0, 255, 0)\n",
        "        correct+=str(count)\n",
        "    return correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBWXMP98vkNn"
      },
      "source": [
        "right_anser1 = {1: ['B'], 2: ['D'], 3: ['A'], 4: ['A'], 5: ['A'], 6: ['A'], 7: ['A'], 8: ['A'], 9: ['C'], 10: ['B'], \n",
        "                   11: ['A'], 12: ['C'], 13: ['A'], 14: ['B'], 15: ['A'], 16: ['C'], 17: ['B'], 18: ['A'], 19: ['C'], 20: ['B'], \n",
        "                   21: ['D'], 22: ['D'], 23: ['B'], 24: ['C'], 25: ['C'], 26: ['C'], 27: ['B'], 28: ['A'], 29: ['B'], 30: ['D'], \n",
        "                   31: ['C'], 32: ['B'], 33: ['C'], 34: ['B'], 35: ['C'], 36: ['D'], 37: ['C'], 38: ['D'], 39: ['A'], 40: ['C'], \n",
        "                   41: ['A'], 42: ['C'], 43: ['C'], 44: ['C'], 45: ['C'], 46: ['D'], 47: ['B'], 48: ['C'], 49: ['C'], 50: ['C'], \n",
        "                   51: ['B'], 52: ['C'], 53: ['A'], 54: ['C'], 55: ['C'], 56: ['A'], 57: ['B'], 58: ['A'], 59: ['D'], 60: ['D'],\n",
        "                   51: ['B'], 52: ['C'], 53: ['A'], 54: ['C'], 55: ['C'], 56: ['A'], 57: ['B'], 58: ['A'], 59: ['D'], 60: ['D'],\n",
        "                   61: ['B'], 62: ['C'], 63: ['A'], 64: ['C'], 65: ['C'], 66: ['A'], 67: ['B'], 68: ['A'], 69: ['D'], 70: ['D'],\n",
        "                   71: ['B'], 72: ['C'], 73: ['A'], 74: ['C'], 75: ['C'], 76: ['A'], 77: ['B'], 78: ['A'], 79: ['D'], 80: ['D'],\n",
        "                   81: ['B'], 82: ['C'], 83: ['A'], 84: ['C'], 85: ['C'], 86: ['A'], 87: ['B'], 88: ['A'], 89: ['D'], 90: ['D'],\n",
        "                   91: ['B'], 92: ['C'], 93: ['A'], 94: ['C'], 95: ['C'], 96: ['A'], 97: ['B'], 98: ['A'], 99: ['D'], 100: ['D'],\n",
        "                   101: ['A'], 102: ['C'], 103: ['D'], 104: ['B'], 105: ['A'], 106: ['C'], 107: ['B'], 108: ['A'], 109: ['C'], 110: ['B'], \n",
        "                   111: ['D'], 112: ['D'], 113: ['B'], 114: ['C'], 115: ['C'], 116: ['C'], 117: ['B'], 118: ['A'], 119: ['B'], 120: ['D']}\n",
        "right_anser2 = {1: ['B'], 2: ['D'], 3: ['A'], 4: ['A'], 5: ['C'], 6: ['B'], 7: ['A'], 8: ['D'], 9: ['C'], 10: ['B'], \n",
        "                   11: ['A'], 12: ['C'], 13: ['D'], 14: ['B'], 15: ['A'], 16: ['C'], 17: ['B'], 18: ['A'], 19: ['C'], 20: ['B'], \n",
        "                   21: ['D'], 22: ['D'], 23: ['B'], 24: ['C'], 25: ['C'], 26: ['C'], 27: ['B'], 28: ['A'], 29: ['B'], 30: ['D'], \n",
        "                   31: ['C'], 32: ['B'], 33: ['C'], 34: ['B'], 35: ['C'], 36: ['D'], 37: ['C'], 38: ['D'], 39: ['A'], 40: ['C'], \n",
        "                   41: ['A'], 42: ['C'], 43: ['C'], 44: ['C'], 45: ['C'], 46: ['D'], 47: ['B'], 48: ['C'], 49: ['C'], 50: ['C'], \n",
        "                   51: ['B'], 52: ['C'], 53: ['A'], 54: ['C'], 55: ['C'], 56: ['A'], 57: ['B'], 58: ['A'], 59: ['D'], 60: ['D'],\n",
        "                   51: ['B'], 52: ['C'], 53: ['A'], 54: ['C'], 55: ['C'], 56: ['A'], 57: ['B'], 58: ['A'], 59: ['D'], 60: ['D'],\n",
        "                   61: ['B'], 62: ['C'], 63: ['A'], 64: ['C'], 65: ['C'], 66: ['A'], 67: ['B'], 68: ['A'], 69: ['D'], 70: ['D'],\n",
        "                   71: ['B'], 72: ['C'], 73: ['A'], 74: ['C'], 75: ['C'], 76: ['A'], 77: ['B'], 78: ['A'], 79: ['D'], 80: ['D'],\n",
        "                   81: ['B'], 82: ['C'], 83: ['A'], 84: ['C'], 85: ['C'], 86: ['A'], 87: ['B'], 88: ['A'], 89: ['D'], 90: ['D'],\n",
        "                   91: ['B'], 92: ['C'], 93: ['A'], 94: ['C'], 95: ['C'], 96: ['A'], 97: ['B'], 98: ['A'], 99: ['D'], 100: ['D'],\n",
        "                   101: ['A'], 102: ['C'], 103: ['D'], 104: ['B'], 105: ['A'], 106: ['C'], 107: ['B'], 108: ['A'], 109: ['C'], 110: ['B'], \n",
        "                   111: ['D'], 112: ['D'], 113: ['B'], 114: ['C'], 115: ['C'], 116: ['C'], 117: ['B'], 118: ['A'], 119: ['B'], 120: ['D']}  \n",
        "#Df1 = pd.DataFrame({'SBD':[sobaodanh],'MaDe':[madethi],'Diem':[correctt]})\n",
        "#Df1.to_excel(\"/content/ket_qua.xlsx\")\n",
        "row = 1\n",
        "col = 0\n",
        "sheet1.col(1).width = 4000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atBfupYUWbNs"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-0LqeL5kqvB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e87957-8322-4b7e-d10c-51a665478159"
      },
      "source": [
        "for k in range(1,5) :\n",
        "  img = cv2.imread(\"/content/tệp_phiếu_thi/phieu\"+str(k)+\".jpg\")\n",
        "  image = img.copy()\n",
        "  #print(\"\",img.shape)\n",
        "  thresh_MDT = find_area(34,image)\n",
        "  thresh_SBD = find_area(7,image)\n",
        "  madethi= findcorrect(thresh_MDT)\n",
        "  sobaodanh= findcorrect(thresh_SBD)\n",
        "  list_ans_boxes = crop_image(img)\n",
        "  list_ans = process_ans_blocks(list_ans_boxes)\n",
        "  list_ans = process_list_ans(list_ans)\n",
        "  results = defaultdict(list)\n",
        "  model = CNN_Model('/content/drive/MyDrive/Auto-Scores-National-Multiple-Choice-Test-master/weight.h5').build_model(rt=True)\n",
        "  results = defaultdict(list)\n",
        "  list_ans = np.array(list_ans)\n",
        "  scores = model.predict_on_batch(list_ans / 255.0)\n",
        "  correctt = 0\n",
        "\n",
        "  if madethi == \"001\":\n",
        "      right_anser = right_anser1\n",
        "  if madethi == \"011\":\n",
        "      right_anser = right_anser2\n",
        "  for idx, score in enumerate(scores):\n",
        "      question = idx // 4\n",
        "      # score [unchoiced_cf, choiced_cf]\n",
        "      if score[1] > 0.9:  # choiced confidence score > 0.9\n",
        "          chosed_answer = map_answer(idx)\n",
        "          results[question + 1].append(chosed_answer)\n",
        "          if right_anser[question+1] == results[question+1]:\n",
        "            correctt+=1\n",
        "  print(\"phieu\"+str(k) )         \n",
        "  print(\"Dap an cua thi sinh la: \",results)\n",
        "  print(\"So Cau Dung la: \",correctt)\n",
        "  print(\"Mã đề thi : \",madethi)\n",
        "  print(\"Số báo danh : \",sobaodanh)\n",
        "  sheet1.write(row, col, k)\n",
        "  sheet1.write(row, col + 1,sobaodanh)\n",
        "  sheet1.write(row, col + 2,madethi)\n",
        "  sheet1.write(row, col + 3,correctt)\n",
        "  row += 1\n",
        "\n",
        "wb.save(\"/content/ket_qua1.xls\") \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f34d4cfef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "phieu1\n",
            "Dap an cua thi sinh la:  defaultdict(<class 'list'>, {1: ['B'], 2: ['D'], 3: ['B', 'C', 'D'], 4: ['A'], 5: ['C'], 6: ['B'], 7: ['A'], 8: ['D'], 9: ['C'], 10: ['B'], 11: ['A'], 12: ['C'], 13: ['D'], 14: ['B'], 15: ['A'], 16: ['C'], 17: ['B'], 18: ['A'], 19: ['C'], 20: ['B'], 21: ['D'], 23: ['B'], 24: ['C'], 26: ['C'], 27: ['B'], 28: ['A'], 29: ['B'], 30: ['D'], 32: ['B'], 34: ['B'], 36: ['D'], 38: ['D'], 39: ['A'], 41: ['A'], 46: ['D'], 47: ['B'], 51: ['B'], 53: ['A'], 56: ['A'], 58: ['B'], 59: ['B'], 60: ['B'], 66: ['A'], 70: ['D'], 73: ['D']})\n",
            "So Cau Dung la:  36\n",
            "Mã đề thi :  001\n",
            "Số báo danh :  112522\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f352c5c1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "phieu2\n",
            "Dap an cua thi sinh la:  defaultdict(<class 'list'>, {1: ['B'], 2: ['D'], 3: ['B', 'C', 'D'], 4: ['A'], 5: ['C'], 6: ['B'], 7: ['A'], 8: ['D'], 9: ['C'], 10: ['B'], 11: ['A'], 12: ['C'], 13: ['D'], 14: ['B'], 15: ['A'], 16: ['C'], 17: ['B'], 18: ['A'], 19: ['C'], 20: ['B'], 21: ['D'], 23: ['B'], 24: ['C'], 26: ['C'], 27: ['B'], 28: ['A'], 29: ['B'], 30: ['D'], 32: ['B'], 33: ['C'], 34: ['B'], 36: ['D'], 37: ['C'], 38: ['D'], 39: ['A'], 40: ['C'], 41: ['A'], 42: ['B'], 43: ['C'], 44: ['B'], 45: ['C'], 46: ['D'], 47: ['B'], 48: ['C'], 49: ['C'], 50: ['C'], 51: ['B'], 52: ['C'], 53: ['A'], 56: ['A'], 57: ['D'], 58: ['B'], 59: ['B'], 60: ['B'], 66: ['A'], 70: ['D'], 73: ['D']})\n",
            "So Cau Dung la:  49\n",
            "Mã đề thi :  011\n",
            "Số báo danh :  250899\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f34d3b78510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "phieu3\n",
            "Dap an cua thi sinh la:  defaultdict(<class 'list'>, {1: ['B'], 2: ['D'], 3: ['B', 'C'], 4: ['A'], 5: ['C'], 6: ['B'], 7: ['A'], 8: ['D'], 9: ['C'], 10: ['B'], 11: ['A'], 12: ['C'], 13: ['D'], 14: ['B'], 15: ['A'], 16: ['C'], 17: ['B'], 18: ['A'], 19: ['C'], 20: ['B'], 21: ['D'], 23: ['B'], 24: ['C'], 26: ['C'], 27: ['B'], 28: ['A'], 29: ['B'], 30: ['D'], 32: ['B'], 34: ['B'], 36: ['D'], 38: ['D'], 39: ['A'], 41: ['A'], 46: ['D'], 47: ['B'], 51: ['B'], 53: ['A'], 56: ['A'], 58: ['B'], 66: ['A'], 70: ['D'], 73: ['D']})\n",
            "So Cau Dung la:  36\n",
            "Mã đề thi :  001\n",
            "Số báo danh :  011467\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f34d4cfe158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "phieu4\n",
            "Dap an cua thi sinh la:  defaultdict(<class 'list'>, {1: ['B'], 2: ['D'], 3: ['B', 'C'], 4: ['A'], 5: ['C'], 6: ['B'], 7: ['A'], 8: ['D'], 9: ['C'], 10: ['B'], 11: ['A'], 12: ['C'], 13: ['D'], 14: ['B'], 15: ['A'], 16: ['C'], 17: ['B'], 18: ['A'], 19: ['C'], 20: ['B'], 21: ['D'], 23: ['B'], 24: ['C'], 26: ['C'], 27: ['B'], 28: ['A'], 29: ['B'], 30: ['D'], 32: ['B'], 34: ['B'], 36: ['D'], 38: ['D'], 39: ['A'], 41: ['A'], 46: ['D'], 47: ['B'], 51: ['B'], 53: ['A'], 56: ['A'], 58: ['B'], 66: ['A'], 70: ['D'], 73: ['D']})\n",
            "So Cau Dung la:  40\n",
            "Mã đề thi :  011\n",
            "Số báo danh :  324234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWIhHFf057gR"
      },
      "source": [
        "#Df1 = pd.DataFrame({'SBD':[sobaodanh],'MaDe':[madethi],'Diem':[correctt]})\n",
        "#Df1.to_excel(\"output.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODJqNT-EQqG5"
      },
      "source": [
        "#df1 = pd.DataFrame({'lkey': ['SBD', 'MaDe', 'Diem'],\n",
        "#                    'value': [sobaodanh, madethi, correctt]})\n",
        "#df1.to_excel(\"output.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcIPwxYE6d4t"
      },
      "source": [
        "#with pd.ExcelWriter('/content/output.xlsx',\n",
        "#                    mode= ) as writer: \n",
        "#    Df2.to_excel(writer,sheet_name='rsi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6xJWym8RaSm"
      },
      "source": [
        "#Df2 = pd.DataFrame({'SBD':[sobaodanh],'MaDe':[madethi],'Diem':[correctt]})\n",
        "#frames = [Df1, Df2]\n",
        "#Df1 = pd.concat(frames)\n",
        "#Df1.to_excel(\"output.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKBrWVPgMnwu"
      },
      "source": [
        "#Df2 = pd.DataFrame({'SBD':[sobaodanh],'MaDe':[madethi],'Diem':[correct]})\n",
        "#Df1.merge(Df2, left_on='lkey', right_on='rkey')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9x1vqmR-fl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762824c8-a254-49af-b402-504927a1f774"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}